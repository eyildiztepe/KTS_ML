# Uygulama {#uygulama}
```{r echo=FALSE,warning=FALSE,message=FALSE}
if(!require(reticulate)) install.packages("reticulate", repos = "http://cran.rstudio.com")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.rstudio.com")
if(!require(caret)) install.packages("caret",repos = "http://cran.rstudio.com")
if(!require(caretEnsemble))  install.packages("caretEnsemble",repos = "http://cran.rstudio.com")
if(!require(doParallel))  install.packages("doParallel",repos = "http://cran.rstudio.com")
if(!require(data.table))  install.packages("data.table",repos = "http://cran.rstudio.com")
if(!require(dplyr))  install.packages("dplyr",repos = "http://cran.rstudio.com")
if(!require(e1071))  install.packages("e1071",repos = "http://cran.rstudio.com")
#if(!require(gbm))  install.packages("gbm",repos = "http://cran.rstudio.com")
if(!require(kernlab))  install.packages("kernlab",repos = "http://cran.rstudio.com")
#if(!require(randomForest))  install.packages("randomForest",repos = "http://cran.rstudio.com")
if(!require(tidyverse))  install.packages("tidyverse",repos = "http://cran.rstudio.com")
#if(!require(xgboost))  install.packages("xgboost",repos = "http://cran.rstudio.com")
if(!require(smotefamily))  install.packages("smotefamily",repos = "http://cran.rstudio.com")
```
```{python echo=FALSE}
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
from warnings import simplefilter
simplefilter(action='ignore', category=FutureWarning)
import numpy as np, pandas as pd, matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_selection import VarianceThreshold
from scipy.stats import f_oneway, chi2_contingency
CTS = pd.read_csv("data/CTS.csv",sep=",")
dataGroup = CTS[["Severity","Age","BMI","CSA","PB","Duration","NRS"]]
dataOverall = CTS[["Age","BMI","CSA","PB","Duration","NRS"]]
meanoval, stdoval = round(dataOverall.mean(),1), round(dataOverall.std(ddof=1),1)
means = round(dataGroup.groupby("Severity").mean(),1)
stds = round(dataGroup.groupby("Severity").std(ddof=1),1)
#####
mild = CTS[CTS.Severity == "mild"]
moderate = CTS[CTS.Severity == "moderate"]
severe = CTS[CTS.Severity == "severe"]
numVar = ["Age","BMI","CSA","PB","Duration","NRS"]
catVar = ["Sex","Side","Diabetes","NP","Weakness"]
p_values = []
p_vals2 = []
for i in numVar:
    _,p_val = f_oneway(mild[i],moderate[i],severe[i])
    p_values.append(round(p_val,3))
for i in catVar:
    var_0 = np.array([sum(mild[i] == 0),sum(moderate[i] == 0),sum(severe[i] == 0)])
    var_1 = np.array([sum(mild[i] == 1),sum(moderate[i] == 1),sum(severe[i] == 1)])
    p_vals2.append(round(chi2_contingency(np.array([var_1,var_0]),correction=False)[1],3))
CTS_kor = CTS.drop(["Severity","Mild","Mod","Sev"],axis=1)
zeroVar = CTS_kor.shape[1]-((VarianceThreshold(threshold=0).fit(CTS_kor)).get_support()).sum()    
##################
catDF = CTS.groupby("Severity").sum()[["Sex","Side","Diabetes","NP","Weakness"]]
sex, rside, diab, np, weak = catDF["Sex"],catDF["Side"],catDF["Diabetes"],catDF["NP"],catDF["Weakness"]
hands = CTS.groupby("Severity").count()["NP"]
handsx = hands*100

```
```{r, echo=FALSE,warning=FALSE,message=FALSE}
  means <- as.data.frame(py$means)
  stds <- as.data.frame(py$stds)
  meanOval <- as.data.frame(t(py$meanoval))
  stdOval <- as.data.frame(t(py$stdoval))
  CTS <- as.data.frame(read_csv("data/CTS.csv"))
  seed<-0923
  set.seed(seed)
  ind<-sample(2,nrow(CTS),replace = T,prob = c(0.7,0.3))
  traindata_top <- CTS[ind==1,]
  testdata_top <- CTS[ind==2,]
  # BURADAN SORNASI R VERİ ÖNİŞLEME
  CTS$Severity<-as.factor(CTS$Severity)
  CTS$Mild<-as.factor(CTS$Mild)
  CTS$Mod<-as.factor(CTS$Mod)
  CTS$Sev<-as.factor(CTS$Sev)
  CTS$Sex <-as.factor(CTS$Sex)
  CTS$Side <-as.factor(CTS$Side)
  CTS$Diabetes <-as.factor(CTS$Diabetes)
  CTS$NP <- as.factor(CTS$NP)
  CTS$Weakness <- as.factor(CTS$Weakness)
  predata<-CTS
  st_model<-preProcess(predata[,5:10], method=c("center","scale"))
  data<-predict(st_model, predata)
  data=as.data.frame(data)
  ohe_feats = c('Sex','Side','Diabetes','NP','Weakness')
  dummies = dummyVars(~ Sex+Side+Diabetes+NP+Weakness, data = data)
  df_ohe <- as.data.frame(predict(dummies, newdata = data))
  df_combined <- cbind(data[,-c(which(colnames(data) %in% ohe_feats))],df_ohe)
  dat = as.data.table(df_combined)
  traindata<-dat[ind==1,]
  testdata<-dat[ind==2,]
  trainmc<-traindata
  testmc<-testdata
  trainmc$Mild=NULL
  trainmc$Mod=NULL
  trainmc$Sev=NULL
  testmc$Mild=NULL
  testmc$Mod=NULL
  testmc$Sev=NULL
  hco <- nrow(CTS)
  hco <- hco * 100
```
```{python echo=FALSE,warning=FALSE,message=FALSE}
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
LE = LabelEncoder().fit(["mild","moderate","severe"])
traindata_P = pd.DataFrame(r.traindata_top)
traindata_P.drop(["Mild","Mod","Sev"],axis=1,inplace=True)
testdata_P = pd.DataFrame(r.testdata_top)
testdata_P.drop(["Mild","Mod","Sev"],axis=1,inplace=True)
X_train, X_test, y_train, y_test = traindata_P.drop(["Severity"],axis=1),testdata_P.drop(["Severity"],axis=1),pd.DataFrame(LE.transform(traindata_P.Severity)),pd.DataFrame(LE.transform(testdata_P.Severity))
Stand = StandardScaler().fit(r.CTS[["Age","BMI","CSA","PB","Duration","NRS"]])
X_train[["Age","BMI","CSA","PB","Duration","NRS"]]=pd.DataFrame(Stand.transform(X_train[["Age","BMI","CSA","PB","Duration","NRS"]]),columns=["Age","BMI","CSA","PB","Duration","NRS"])
y_train = y_train.to_numpy().ravel()
X_test[["Age","BMI","CSA","PB","Duration","NRS"]] = pd.DataFrame(Stand.transform(X_test[["Age","BMI","CSA","PB","Duration","NRS"]]),columns=["Age","BMI","CSA","PB","Duration","NRS"])
y_test = y_test.to_numpy().ravel()
```  
Bu bölümde yapılan uygulama sunulmuştur. Uygulamada kullanılan veriler 2021 yılında Güney Kore'de yapılan bir araştırmadan alınmıştır [@park2021machine]. Uzmanlar tarafından yapılan tetkikler ile her bir hasta için (her bir el için) ciddiyet sınıflandırılması mild, moderate, severe olarak belirlenmiştir. Çalışmada 1037 elden alınan verilerin 405 (39.05%) adedi erkek hastalardan,  632 (60.95%) adedi kadın hastalardan elde edilmiştir. Uzmanlar tarafından 1037 adet elin, 507 (48.9%) adedi mild, 276 (26.6%) adedi moderate ve 254 (24.5%) adedi severe olarak sınıflandırılmıştır.  

Araştırmada uzman hekimler tarafından hastalara yöneltilen sorular ile şikayetleri olan ellerine ilişkin aşağıdaki değişkenler için veri toplanmıştır;  

* Hands (Eller)  

* Age (Yaş)  

* Sex (Cinsiyet)  

* BMI (Body-mass index, Vücut kitle indeksi)  

* Side (Right side involvement, Sağ Elde Bulgu)  

* Diabetes (Diyabet Hastalığı Durumu)  

* Duration (Duration in months, Dayanma süresi (Aylık))  

* NRS (Numeric rating scale of pain, Hissedilen acının numerik karşılığı)  

* NP (Noctural Pain, Gece Ağrıları)  

* Weakness (Tenar weakness and/or atrophy, Avuç İçi Zayıflık ve/veya Körelme)  

* CSA (Cyclosporine dosage in $mm^2$, Siklosporin dozu ($mm^2$))  

* PB (fexor retinaculum in mm, Fleksör retinakulum (mm))  


|                                    | Overall |
|:-----------------------------------|--------:|
| Age,years (mean $\pm$ SD)          | `r meanOval$Age` $\pm$ `r stdOval$Age` |
| BMI, kg/m$^2$ (mean $\pm$ SD)      | `r meanOval$BMI` $\pm$ `r stdOval$BMI` |
| Duration, months (mean $\pm$ SD)   | `r meanOval$Duration` $\pm$ `r stdOval$Duration` |
| NRS (mean $\pm$ SD)                | `r meanOval$NRS` $\pm$ `r stdOval$NRS` |
| CSA, mm$^2$ (mean $\pm$ SD)        | `r meanOval$CSA` $\pm$ `r stdOval$CSA` |
| PB, mm (mean $\pm$ SD)             | `r meanOval$PB` $\pm$ `r stdOval$PB` |

Table: (\#tab:overall) Sayısal Değişkenlerin Tanımlayıcı İstatistikleri

|                                    | Mild                                | Moderate                            | Severe                              | P Value |
|:-----------------------------------|------------------------------------:|------------------------------------:|------------------------------------:|--------:|
| Age,years (mean $\pm$ SD)          | `r means$Age[1]` $\pm$ `r stds$Age[1]` | `r means$Age[2]` $\pm$ `r stds$Age[2]` | `r means$Age[3]` $\pm$ `r stds$Age[3]` | `r py$p_values[1]`|
| BMI, kg/m$^2$ (mean $\pm$ SD)      | `r means$BMI[1]` $\pm$ `r stds$BMI[1]` | `r means$BMI[2]` $\pm$ `r stds$BMI[2]` | `r means$BMI[3]` $\pm$ `r stds$BMI[3]` | `r py$p_values[2]`|
| Duration, months (mean $\pm$ SD)   | `r means$Duration[1]` $\pm$ `r stds$Duration[1]` | `r means$Duration[2]` $\pm$ `r stds$Duration[2]` | `r means$Duration[3]` $\pm$ `r stds$Duration[3]` | `r py$p_values[3]`|
| NRS (mean $\pm$ SD)                | `r means$NRS[1]` $\pm$ `r stds$NRS[1]` | `r means$NRS[2]` $\pm$ `r stds$NRS[2]` | `r means$NRS[3]` $\pm$ `r stds$NRS[3]` | `r py$p_values[4]`|
| CSA, mm$^2$ (mean $\pm$ SD)        | `r means$CSA[1]` $\pm$ `r stds$CSA[1]` | `r means$CSA[2]` $\pm$ `r stds$CSA[2]` | `r means$CSA[3]` $\pm$ `r stds$CSA[3]` | `r py$p_values[5]`|
| PB, mm (mean $\pm$ SD)             | `r means$PB[1]` $\pm$ `r stds$PB[1]` | `r means$PB[2]` $\pm$ `r stds$PB[2]` | `r means$PB[3]` $\pm$ `r stds$PB[3]` | `r py$p_values[6]`|

Table: (\#tab:sayisal) Değişkenlerin Bağımlı Değişkene Göre Tanımlayıcı İstatistikleri \footnotesize (P-Value Değerleri Tek Yönlü Varyans Analiz Testi ile Elde Edilmiştir.)  

\
\
\  


|                                          | Mild | Moderate | Severe | P value |
|------------------------------------------|-----:|---------:|-------:|-------:|
| Eller,  n (%)                            |`r py$hands[1]` (`r round((py$handsx[1]/hco)*100,1)`)|`r py$hands[2]` (`r round((py$handsx[2]/hco)*100,1)`)|`r py$hands[3]` (`r round((py$handsx[3]/hco)*100,1)`)|    -    |
| Cinsiyet (Kadın), n (%)                  |`r py$sex[1]` (`r round(py$sex[1]/sum(CTS["Mild"] == "mild")*100,1)`)|`r py$sex[2]` (`r round(py$sex[2]/sum(CTS["Mod"] == "moderate")*100,1)`)|`r py$sex[3]` (`r round(py$sex[3]/sum(CTS["Sev"] == "severe")*100,1)`)| `r py$p_vals2[1]`|
| Sağ Elde Bulgu, n (%)                  |`r py$rside[1]` (`r round(py$rside[1]/sum(CTS["Mild"] == "mild")*100,1)`)|`r py$rside[2]` (`r round(py$rside[2]/sum(CTS["Mod"] == "moderate")*100,1)`)|`r py$rside[3]` (`r round(py$rside[3]/sum(CTS["Sev"] == "severe")*100,1)`)| `r py$p_vals2[2]`|
| Diyabet, n (%)                           |`r py$diab[1]` (`r round(py$diab[1]/sum(CTS["Mild"] == "mild")*100,1)`)|`r py$diab[2]` (`r round(py$diab[2]/sum(CTS["Mod"] == "moderate")*100,1)`)|`r py$diab[3]` (`r round(py$diab[3]/sum(CTS["Sev"] == "severe")*100,1)`)| `r py$p_vals2[3]`|
| Gece Ağrıları, n (%)                     |`r py$np[1]` (`r round(py$np[1]/sum(CTS["Mild"] == "mild")*100,1)`)|`r py$np[2]` (`r round(py$np[2]/sum(CTS["Mod"] == "moderate")*100,1)`)|`r py$np[3]` (`r round(py$np[3]/sum(CTS["Sev"] == "severe")*100,1)`)| `r py$p_vals2[4]`|
| Avuç İçi Zayıflık ve/veya Körelme, n (%) |`r py$weak[1]` (`r round(py$weak[1]/sum(CTS["Mild"] == "mild")*100,1)`)|`r py$weak[2]` (`r round(py$weak[2]/sum(CTS["Mod"] == "moderate")*100,1)`)|`r py$weak[3]` (`r round(py$weak[3]/sum(CTS["Sev"] == "severe")*100,1)`)| `r py$p_vals2[5]`|

Table: (\#tab:catvar) Katagorik Değişkenlerin Bağımlı Değişkence Frekans Dağılımı \footnotesize (P-Value Değerleri Ki-Kare Bağımsızlık Testi ile Elde Edilmiştir.)   

Kullanılan verilere ait tanımlayıcı istatistikler Tablo \ref{tab:overall}, Tablo \ref{tab:sayisal} ve Tablo \ref{tab:catvar} de verilmiştir. Varsayım kontrollerinin ardından sayısal değişkenlerin ciddiyet sınıflarına göre farklılık gösterip göstermediği tek yönlü varyans analizi ile araştırılmıştır ($\alpha = 0.05$). Tablo \ref{tab:sayisal}'de yer alan P-Value değerleri incelendiğinde ciddiyet sınıflamasının yaşa göre anlamlı bir değişim göstermediği diğer tüm değişkenler için anlamlı bir fark olduğu görülmüştür.  

Tablo \ref{tab:catvar}'te yer alan P-Value değerleri incelendiğinde ciddiyet sınıflamasının KTS'nin sağ veya sol elde görülmesine göre anlamlı bir değişim göstermediği diğer tüm değişkenler için anlamlı bir fark olduğu görülmüştür.  

\  
\  

Bu çalışmada, KTS ciddiyet sınıflandırması için K-En Yakın Komşuluk, Rassal Ormanlar, Yapay Sinir Ağları ve XGBoost yöntemleri kullanılmıştır.  
İlk olarak orijinal verilerdeki 3 sınıf (Mild, Moderate, Severe) için sınıflandırma hedeflenmiştir.  
Bölüm \ref{multiclass}'de bu problem için farklı modeller ile elde edilen sonuçlara yer verilmiştir.  
Uygulamanın ikinci bölümünde hedef değişken iki sınıfa indirgenmiş ve bu probleme ait sonuçlar bölüm \ref{binary}'de paylaşılmıştır.  
Uygulamada Python programlama dili  ve Scikit-Learn, Pandas, Numpy, Matplotlib, XGBoost kütüphanelerinden yararlanılmıştır.  
Bu bölümde modellerin performanslarını değerlendirmek üzere kesinlik, duyarlılık, F1-skoru, doğruluk oranı, dengelenmiş doğruluk oranı hesaplanmıştır.

```{python echo=FALSE}
from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix, ConfusionMatrixDisplay, auc
import pandas as pd
from sklearn.multiclass import OneVsRestClassifier
import matplotlib.pyplot as plt
from itertools import cycle
from sklearn.preprocessing import label_binarize
def roc(model):
    """ Unfitted model"""
    model_name = str(model.__class__).split(".")[-1][:-2]
    model = OneVsRestClassifier(model).fit(X_train,y_train)
    plt.figure()
    y_pred = model.predict_proba(X_test)
    fpr = dict()
    tpr = dict()
    thresh = dict()
    thresh_df = pd.DataFrame(columns=["Class","Threshold"])
    roc_auc = dict()
    for i in range(3):
        fpr[i], tpr[i], thresh[i] = roc_curve(y_test, y_pred[:, i],pos_label=i)
        roc_auc[i] = auc(fpr[i], tpr[i])
    for i,j in zip(thresh.keys(),["mildVsAll","modVsAll","sevVsAll"]):
        thresh[j] = thresh.pop(i)
        if j == "sevVsAll" : break
    for i,j in zip(thresh.keys(),thresh.values()):
        for x in j:
            thresh_df = thresh_df.append({"Class":i,"Threshold":x},ignore_index=True)
    thresh_df.to_csv(f'data/thresholds_{model_name}.csv',index=False)
    colors = cycle(["aqua", "darkorange", "cornflowerblue"])
    for i, color, j in zip(range(3), colors,["Mild","Moderate","Severe"]):
        plt.plot(
            fpr[i],
            tpr[i],
            color=color,
            lw=2,
            label="ROC curve of class {0} (area = {1:0.2f})".format(j, roc_auc[i])
        )
    plt.plot([0, 1], [0, 1], "k--", lw=2)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel("Yanlış Pozitif Oranı")
    plt.ylabel("Doğru Pozitif Oranı")
    plt.title("ROC Eğrileri")
    plt.legend(loc="lower right")
    plt.savefig(f'figure/roc_curve_{model_name}.png')
```  
## Çok Sınıflı(Multiclass) Sınıflama Problemi {#multiclass}
Bu bölümde KTS ciddiyet sınıflandırması için hedef değişkenin 3 farklı ciddiyet düzeyine sahip olduğu durumda farklı sınıflama algoritmaları ile ciddiyet düzeyinin tahminlenmesi amaçlanmıştır.  

### K-En Yakın Komşuluk Modeli  {#mult_knn}
Bu bölümde veri seti üzerinde K - En yakın komşuluk modeli kullanılmış ve çıktıları değerlendirilmiştir.  

#### Hiper Parametre Seçimi  
Daha önce belirlenen parametre uzayını ve Scikit-Learn kütüphanesinde bulunan GridSearchCV algoritması ile en yüksek doğruluk oranı yakalanana kadar çalışması sağlanmıştır.
```{python echo=FALSE}
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix,classification_report,balanced_accuracy_score
KNN_model = KNeighborsClassifier()
#params = {"n_neighbors":np.arange(5,200),
#          "weights":["uniform", "distance"],
#          "algorithm":["auto","ball_tree","kd_tree","brute"]}
#GSC = GridSearchCV(KNN_model,param_grid=params,
#                   cv=10,verbose=1,scoring="accuracy").fit(X_train,y_train)
#pd.DataFrame(GSC.cv_results_).to_csv("data/KNN_GridSearch_Results.csv",index=False)
knn = pd.read_csv("data/KNN_GridSearch_Results.csv")
plt.figure(figsize=(10,5),dpi=60);
sns.lineplot(x=knn.param_n_neighbors,y=knn.mean_test_score*100,hue=knn.param_weights);
plt.ylabel("Eğitim Verisi Doğruluk Skoru (%)");
plt.xlabel("Komşu Sayısı");
plt.legend(title="Ağırlıklandırma",loc="upper right",labels=["Eşit Ağırlıklandırma","Uzaklığa Göre Ağırlıklandırma"]);
plt.savefig("figure/KNN_Grid_Graph.png");
```
```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı K-NN Eğitim Verisi Doğruluk Skorları",out.width="110%",out.height="55%"}
knitr::include_graphics(path="figure/KNN_Grid_Graph.png")
```
```{python echo=FALSE}
#print(f'En İyi Parametreler : {GSC.best_params_}')
```  
K-En yakın komşuluk modeli için en yüksek doğruluk oranı aşağıdaki parametreler ile bulunmuştur;  

* 'algorithm':'auto'
* 'n_neighbors':33
* 'weights':'distance'  

\newpage

#### En İyi Parametreli Model
Bulunan parametrelerle kurulan modelin sınıflandırma metrikleri aşağıdaki gibidir.
```{python echo=FALSE}
KNN_model = KNeighborsClassifier(n_neighbors = 33,
                                 weights ='distance').fit(X_train,y_train)
y_pred = KNN_model.predict(X_test)
print(classification_report(y_test,y_pred,target_names=["Mild","Moderate","Severe"]))
print(f'Balanced Accuracy Score : {balanced_accuracy_score(y_test,y_pred)}')
```
```{python echo=FALSE}
ConfusionMatrixDisplay(confusion_matrix(y_test,y_pred),display_labels=["Mild","Moderate","Severe"]).plot();
plt.savefig("figure/knn_conf.png");
```
```{python echo=FALSE}
roc(KNeighborsClassifier(n_neighbors = 33,
                                 weights ='distance'))
```

```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı K-NN Modeli Karmaşıklık Matrisi",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/knn_conf.png")
```
```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı K-NN Modeli ROC Eğrisi ve AUC Değerleri",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/roc_curve_KNeighborsClassifier.png")
```
### Rassal Ormanlar Modeli  {#mult_rf}
Bu bölümde veri seti üzerinde rassal ormanlar modeli kullanılmış ve çıktıları değerlendirilmiştir.  

#### Hiper Parametre Seçimi  
Daha önce belirlenen parametre uzayını ve Scikit-Learn kütüphanesinde bulunan GridSearchCV algoritması ile en yüksek doğruluk oranı yakalanana kadar çalışması sağlanmıştır.
```{python,out.height="10%",echo=FALSE}
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix,classification_report,balanced_accuracy_score
RFC_model = RandomForestClassifier()
#param_grid = {"n_estimators":np.arange(350,1000,50),
              #"criterion":["gini","index"],
              #"max_features":["auto","sqrt","log2"],
              #"ccp_alpha":[0.01,0.05,.1,0.3,.5,.7,.9,1],
              #"max_samples":np.arange(1,X_train.shape[1],1)}
#GSC = GridSearchCV(RFC_model,param_grid=params,
                   #cv=10,verbose=1,scoring="accuracy",random_state=13).fit(X_train,y_train)
results = pd.read_csv("data/RF_GridSearch_Results.csv")
ginis = results[results["param_criterion"] == "gini"]
ginis = ginis[ginis["param_ccp_alpha"] <= 0.1]
ginis = ginis[ginis["mean_test_score"]>=0.704]
#Grafik Çizimi
plt.figure(figsize=(10,5),dpi=60);
plt.ylim(0.703*100,round(ginis.mean_test_score.unique().max()*100,2)+0.1);
sns.lineplot(y=ginis.mean_test_score*100,x=ginis.param_n_estimators,hue=ginis.param_ccp_alpha,palette=sns.color_palette(n_colors=3),err_style=None);
plt.ylabel("Eğitim Verisi Doğruluk Skoru (%)");
plt.xlabel("Ormandaki Ağaç Sayısı");
plt.legend(title="Ccp Alpha",loc="upper right",labels=[0.01,0.05,0.1]);
plt.savefig("figure/RF_Grid_Graph.png");
```
```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı Rassal Ormanlar Modeli Eğitim Verisi Doğruluk Skorları",out.width="110%",out.height="50%"}
knitr::include_graphics(path="figure/RF_Grid_Graph.png")
```
```{python echo=FALSE}
#print(f'En İyi Parametreler : {GSC.best_params_}')
```
Rassal ormanlar modeli için en yüksek doğruluk oranı aşağıdaki parametreler ile bulunmuştur;  

* 'ccp_alpha':0.05
* 'criterion':'gini'
* 'weights':'distance'
* 'max_features':'auto'
* 'max_samples':10
* 'n_estimators':350  

\newpage

#### En İyi Parametreli Model
Bulunan parametrelerle kurulan modelin sınıflandırma metrikleri aşağıdaki gibidir.
```{python echo=FALSE}
RFC_model = RandomForestClassifier(ccp_alpha=0.05,criterion="gini",max_features="auto",
                                   max_samples=10,n_estimators=350,random_state=13).fit(X_train,y_train)
y_pred = RFC_model.predict(X_test)
print(classification_report(y_test,y_pred,target_names=["Mild","Moderate","Severe"]))
print(f'Balanced Accuracy Score : {balanced_accuracy_score(y_test,y_pred)}')
```

```{python echo=FALSE}
ConfusionMatrixDisplay(confusion_matrix(y_test,y_pred),display_labels=["Mild","Moderate","Severe"]).plot();
plt.savefig("figure/rfc_conf.png")
```
```{python echo=FALSE}
roc(RandomForestClassifier(ccp_alpha=0.01,criterion="gini",max_features="sqrt",
                                   max_samples=10,n_estimators=900,random_state=13))
```

```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı Rassal Ormanlar Modeli Karmaşıklık Matrisi",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/rfc_conf.png")
```
```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı Rassal Ormanlar Modeli ROC Eğrisi ve AUC Değerleri",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/roc_curve_RandomForestClassifier.png")
```
### eXtreme Gradient Boosting (XGBoost)  {#mult_xgb}
Bu bölümde veri seti üzerinde XGBoost modeli kullanılmış ve çıktıları değerlendirilmiştir.    

#### Hiper Parametre Seçimi  
Daha önce belirlenen parametre uzayını ve Scikit-Learn kütüphanesinde bulunan GridSearchCV algoritması ile en yüksek doğruluk oranı yakalanana kadar çalışması sağlanmıştır.
```{python,out.height="10%",echo=FALSE}
from xgboost.sklearn import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix,classification_report,balanced_accuracy_score
XGB_model = XGBClassifier()
#param_grid = {"booster":["gbtree","gblinear"],
#              "eta":np.arange(0,1,0.1),
#              "min_child_weight":np.arange(0,5,1),
#              "max_depth":np.arange(3,10,1),
#              "gamma":np.arange(0,1,0.1),
#              "sumsample":np.arange(0,1,0.1),
#              "colsample_bytree":np.arange(0,1,.1),
#              "n_estimators":np.arange(0,1000,50),
#              "objective":["multi:softmax","multi:softprob"],
#              "eval_metric":["auc"],
#              "use_label_encoder":[False]}
#GSC = GridSearchCV(XGB_model,param_grid=param_grid,cv=10,verbose=1,n_jobs=-1,scoring="accuracy").fit(X_train,y_train)
resultsxgb = pd.read_csv("data/XGBoost_GridSearch_Results.csv",sep=";")
resultsxgb = resultsxgb.sort_values("rank_test_score")
sorted_xgb = resultsxgb[["param_booster","param_eta","param_max_depth","param_min_child_weight","param_n_estimators","param_objective","mean_test_score","rank_test_score"]]
#Grafik Çizimi
plt.figure(figsize=(15,10),dpi=100);
plt.ylim(0.72*100,round(sorted_xgb.mean_test_score.unique().max()*100,2)+0.05);
for i in sorted_xgb.param_eta.unique():
    if i <=0.4:
        x = sorted_xgb[sorted_xgb.param_eta == i].groupby("param_n_estimators").max()
        sns.lineplot(x=x.index,y=x.mean_test_score*100);
plt.ylabel("Eğitim Verisi Doğruluk Skoru (%)");
plt.xlabel("Ağaç Sayısı");
plt.legend([.1,.4,.2,.3],loc=1,title="Learning Rate (eta)");
plt.savefig("figure/XGB_Grid_Graph.png");
```
```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı XGBoost Modeli Eğitim Verisi Doğruluk Skorları",out.width="110%",out.height="50%"}
knitr::include_graphics(path="figure/XGB_Grid_Graph.png")
```
```{python echo=FALSE}
#print(f'En İyi Parametreler : {GSC.best_params_}')
```
XGBoost modeli için en yüksek doğruluk oranı aşağıdaki parametreler ile bulunmuştur;  

* 'eta':0.1
* 'max_depth':3
* 'min_child_weight':10
* 'n_estimators':100
* 'objective':'multi:softprob'
* 'sumsample':0.5  

\newpage  

Bulunan parametrelerle kurulan modelin sınıflandırma metrikleri aşağıdaki gibidir.
```{python echo=FALSE}
XGB_model = XGBClassifier(booster="gbtree",eta="0.1",max_depth=3,min_child_weight=10,n_estimators=100,objective="multi:softprob",eval_metric="auc",use_label_encoder=False,num_class=2).fit(X_train,y_train)
y_pred = XGB_model.predict(X_test)
print(classification_report(y_test,y_pred,target_names=["Mild","Moderate","Severe"]))
print(f'Balanced Accuracy Score : {balanced_accuracy_score(y_test,y_pred)}')
```
```{python echo=FALSE}
ConfusionMatrixDisplay(confusion_matrix(y_test,y_pred),display_labels=["Mild","Moderate","Severe"]).plot();
plt.savefig("figure/xgb_conf.png");
```
```{python echo=FALSE}
roc(XGBClassifier(booster="gbtree",eta="0.1",max_depth=3,min_child_weight=10,n_estimators=100,objective="multi:softprob",eval_metric="auc",use_label_encoder=False,num_class=2))
```
```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı XGBoost Modeli Karmaşıklık Matrisi",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/xgb_conf.png")
```
```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı XGBoost Modeli ROC Eğrisi ve AUC Değerleri",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/roc_curve_XGBClassifier.png")
```  
### Yapay Sinir Ağları (Neural Networks) {#mult_nn}
Bu bölümde veri seti üzerinde yapay sinir ağları modeli kullanılmış ve çıktıları değerlendirilmiştir.  

#### Hiper Parametre Seçimi  
Daha önce belirlenen parametre uzayını ve Scikit-Learn kütüphanesinde bulunan GridSearchCV algoritması ile en yüksek doğruluk oranı yakalanana kadar çalışması sağlanmıştır.
```{python,out.height="10%",echo=FALSE}
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix,classification_report,balanced_accuracy_score
#params = {"hidden_layer_sizes":np.arange(1,26,1),
          #"learning_rate":["adaptive","constant","invscaling"],
          #"activation":["identity","logistic","tanh","relu"]}
#gridd = GridSearchCV(MLPClassifier(random_state=13),param_grid=params,cv=10,verbose=1,n_jobs=-1,scoring="accuracy").fit(X_train,y_train)
#pd.DataFrame(gridd.cv_results_).to_csv("NN_GridSearch_Results.csv",sep=";",index=False)
result_nn = pd.read_csv("data/NN_GridSearch_Results.csv",sep=";")
#Grafik Çizimi
plt.figure(figsize=(15,10),dpi=100);
sns.lineplot(x=result_nn["param_hidden_layer_sizes"],y=result_nn["mean_test_score"]*100,hue=result_nn["param_activation"]);
plt.xlabel("Katman Sayısı");
plt.ylabel("Eğitim Verisi Doğruluk Skoru (%)");
plt.legend(title="Aktivasyon Fonksiyonu");
plt.savefig("figure/NN_Grid_Graph.png");
```
```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı Yapay Sinir Ağları Modeli Eğitim Verisi Doğruluk Skorları",out.width="110%",out.height="50%"}
knitr::include_graphics(path="figure/NN_Grid_Graph.png")
```
```{python echo=FALSE}
#print(f'En İyi Parametreler : {gridd.best_params_}')
```
Yapay sinir ağları modeli için en yüksek doğruluk oranı aşağıdaki parametreler ile bulunmuştur;  

* 'activation':'relu'
* 'hidden_layer_sizes:19
* 'learning_rate':'adaptive'  

\newpage  

Bulunan parametrelerle kurulan modelin sınıflandırma metrikleri aşağıdaki gibidir.
```{python echo=FALSE}
NN_model = MLPClassifier(activation="relu",hidden_layer_sizes=19,learning_rate="adaptive",random_state=13,max_iter=3000).fit(X_train,y_train)
y_pred = NN_model.predict(X_test)
print(classification_report(y_test,y_pred,target_names=["Mild","Moderate","Severe"]))
print(f'Balanced Accuracy Score : {balanced_accuracy_score(y_test,y_pred)}')
```

```{python echo=FALSE}
ConfusionMatrixDisplay(confusion_matrix(y_test,y_pred),display_labels=["Mild","Moderate","Severe"]).plot();
plt.savefig("figure/nn_conf.png")
```
```{python echo=FALSE}
roc(MLPClassifier(activation="relu",hidden_layer_sizes=19,learning_rate="adaptive",random_state=13,max_iter=3000))
```

```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı Yapay Sinir Ağları Modeli Karmaşıklık Matrisi",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/nn_conf.png")
```
```{r echo=FALSE,fig.align="center",fig.cap="Üç Sınıflı Yapay Sinir Ağları Modeli ROC Eğrisi ve AUC Değerleri",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/roc_curve_MLPClassifier.png")
```  
### Çok Sınıflı Sınıflama Probleminin Modellerinin Değerlendirdirilmesi  
Bölüm \ref{mult_knn}, \ref{mult_rf}, \ref{mult_xgb} ve \ref{mult_nn}'den elde edilen sonuçlar incelenmiş olup, üç sınıflı problem için %77 doğru sınıflama oranı ile en iyi model XGBoost olarak bulunmuştur.  
Bölüm \ref{mult_xgb}'de bulunan performans metrikleri yakından incelendiğinde, duyarlılık metriği 'Moderate' ve 'Severe' sınıfları için 'Mild' sınıfına kıyasla daha düşük kalmıştır.  
Duyarlılık metriğindeki düşüklüğün sebep olabileceği yanlış sınıflandırmaların önüne geçebilmek amacı ile bölüm \ref{binary}'de problem iki sınıflı probleme indirgenecek ve modeller tekrar çalıştırılacaktır.

## İki Sınıflı Sınıflama  {#binary}
Bu bölümde KTS ciddiyet sınıflandırması için hedef değişkenin 3 farklı ciddiyet düzeyine sahip olduğu veri seti 'Moderate' ve 'Severe' ciddiyet düzeyleri birleştirilerek problemin 2 farklı ciddiyet düzeyine indirgenip farklı sınıflama algoritmaları ile ciddiyet düzeyinin tahminlenmesi amaçlanmıştır.  

```{python echo=FALSE}
from sklearn.model_selection import train_test_split
bin_data = pd.read_csv("data/binary_data.csv",sep=";")
X_bin = bin_data.drop(["Severity","New_Sev"],axis=1)
y_bin = bin_data["New_Sev"]
Xbin_train, Xbin_test, ybin_train, ybin_test = train_test_split(X_bin,y_bin,test_size=0.3,stratify=y_bin,random_state=13)
def roc_bin(model):
    model_name = str(model.__class__).split(".")[-1][:-2]
    ybin_pred2 = model.predict_proba(Xbin_test)[::, 1]
    plt.figure(figsize=(10,5),dpi=100)
    fpr, tpr, thresh = roc_curve(ybin_test, ybin_pred2)
    roc_auc = auc(fpr, tpr)
    plt.plot(
        fpr,
        tpr,
        lw=2,
        label=f"AUC = {roc_auc}"
        )
    plt.plot([0, 1], [0, 1], "k--", lw=2)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel("Yanlış Pozitif Oranı")
    plt.ylabel("Doğru Pozitif Oranı")
    plt.title("ROC Eğrisi")
    plt.legend(loc="lower right")
    plt.savefig(f'figure/{model_name}_binary_roc.png')
```

### K-En Yakın Komşuluk Modeli  {#bin_knn}

Bu bölümde veri seti üzerinde K - En yakın komşuluk modeli kullanılmış ve çıktıları değerlendirilmiştir.  

#### Hiper Parametre Seçimi  

Daha önce belirlenen parametre uzayını ve Scikit-Learn kütüphanesinde bulunan GridSearchCV algoritması ile en yüksek doğruluk oranı yakalanana kadar çalışması sağlanmıştır.    

```{python echo=FALSE}
#KNN_model_bin = KNeighborsClassifier()
#params = {"n_neighbors":np.arange(5,200),
          #"weights":["uniform", "distance"],
          #"algorithm":["auto","ball_tree","kd_tree","brute"]}
#GSC = GridSearchCV(KNN_model_bin,param_grid=params,cv=10,verbose=1,scoring="accuracy",n_jobs=-1).fit(Xbin_train,ybin_train)
#pd.DataFrame(GSC.cv_results_).to_csv("data/KNN_bin_GridSearch_Results.csv",index=False)
knn_bin = pd.read_csv("data/KNN_bin_GridSearch_Results.csv",sep=";")
plt.figure(figsize=(10,5),dpi=60);
sns.lineplot(x=knn_bin["param_n_neighbors"],y=knn_bin["mean_test_score"]*100,hue=knn_bin["param_weights"]);
plt.ylabel("Eğitim Verisi Doğruluk Skoru (%)");
plt.xlabel("Komşu Sayısı");
plt.legend(title="Ağırlıklandırma",loc="upper right",labels=["Eşit Ağırlıklandırma","Uzaklığa Göre Ağırlıklandırma"]);
plt.savefig("figure/KNN_bin_Grid_Graph.png");
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı K-NN Modeli Eğitim Verisi Doğruluk Skorları",out.width="110%",out.height="55%"}
knitr::include_graphics(path="figure/KNN_bin_Grid_Graph.png")
```
```{python echo=FALSE}
#print(f'En İyi Parametreler : {GSC.best_params_}')
```
\newpage  
K-En yakın komşuluk modeli için en yüksek doğruluk oranı aşağıdaki parametreler ile bulunmuştur;  

* 'algorithm':'auto'    
* 'n_neighbors':23  
* 'weights':'uniform'  

#### En İyi Parametreli Model  

Bulunan parametrelerle kurulan modelin sınıflandırma metrikleri aşağıdaki gibidir.    

```{python echo=FALSE}
KNN_modelbin = KNeighborsClassifier(n_neighbors = 23,
                                 weights ='uniform').fit(Xbin_train,ybin_train)
ybin_pred = KNN_modelbin.predict(Xbin_test)
print(classification_report(ybin_test,ybin_pred,target_names=["Mild","Mod+Sev"]))
print(f'Balanced Accuracy Score : {balanced_accuracy_score(ybin_test,ybin_pred)}')
```

```{python echo=FALSE}
ConfusionMatrixDisplay(confusion_matrix(ybin_test,ybin_pred),display_labels=["Mild","Mod+Sev"]).plot();
plt.savefig("figure/knn_bin_conf.png")
```
```{python echo=FALSE}
roc_bin(KNN_modelbin)
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı K-NN Modeli Karmaşıklık Matrisi",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/knn_bin_conf.png")
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı K-NN Modeli ROC Eğrisi ve AUC Değerleri",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/KNeighborsClassifier_binary_roc.png")
```  
### Rassal Ormanlar Modeli {#bin_rf}

Bu bölümde veri seti üzerinde rassal ormanlar modeli kullanılmış ve çıktıları değerlendirilmiştir.    

#### Hiper Parametre Seçimi  

Daha önce belirlenen parametre uzayını ve Scikit-Learn kütüphanesinde bulunan GridSearchCV algoritması ile en yüksek doğruluk oranı yakalanana kadar çalışması sağlanmıştır.  

```{python echo=FALSE}
#param_grid = {"n_estimators":np.arange(350,700,50),
              #"max_features":["auto","sqrt","log2"],
              #"ccp_alpha":[0.01,0.05,.1,0.3,.5],
              #"max_samples":np.arange(1,X_train.shape[1],1)}
#GSC = GridSearchCV(RandomForestClassifier(random_state=13,criterion="gini"),param_grid=param_grid,cv=10,verbose=1,n_jobs=-1,scoring="accuracy").fit(Xbin_train,ybin_train)

#pd.DataFrame(GSC.cv_results_).to_csv("data/RF_bin_Grid_Res.csv",index=False)

rf_bin = pd.read_csv("data/RF_bin_Grid_Res.csv",sep=";")
maxed = rf_bin.groupby("rank_test_score").max()
maxed = maxed[maxed["mean_test_score"] > 0.75]
plt.figure(figsize=(15,10),dpi=100);
sns.lineplot(x="param_n_estimators",y="mean_test_score",hue="param_ccp_alpha",data=maxed,err_style=None,palette="husl");
plt.xlabel("Ormandaki Ağaç Sayısı");
plt.ylabel("Eğitim Verisi Doğruluk Skoru (%)");
plt.legend(title="Ccp Alpha");
plt.savefig("figure/RF_bin_Grid_Graph.png");
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı Rassal Ormanlar Modeli Eğitim Verisi Doğruluk Skorları",out.width="110%",out.height="55%"}
knitr::include_graphics(path="figure/RF_bin_Grid_Graph.png")
```
```{python echo=FALSE}
#print(f'En İyi Parametreler : {GSC.best_params_}')
```  
Rassal ormanlar modeli için en yüksek doğruluk oranı aşağıdaki parametreler ile bulunmuştur;  

* 'ccp_alpha': 0.01  
* 'max_features': 'auto'  
* 'max_samples': 10  
* 'n_estimators': 400  
\newpage  

#### En İyi Parametreli Model  

Bulunan parametrelerle kurulan modelin sınıflandırma metrikleri aşağıdaki gibidir.   

```{python echo=FALSE}
RF_modelbin = RandomForestClassifier(ccp_alpha = 0.01, 
                                     max_features = "auto",
                                     max_samples = 10,
                                     n_estimators = 400).fit(Xbin_train,ybin_train)
ybin_pred = RF_modelbin.predict(Xbin_test)
print(classification_report(ybin_test,ybin_pred,target_names=["Mild","Mod+Sev"]))
print(f'Balanced Accuracy Score : {balanced_accuracy_score(ybin_test,ybin_pred)}')
```

```{python echo=FALSE}
ConfusionMatrixDisplay(confusion_matrix(ybin_test,ybin_pred),display_labels=["Mild","Mod+Sev"]).plot();
plt.savefig("figure/rf_bin_conf.png");
```
```{python echo=FALSE}
roc_bin(RF_modelbin)
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı Rassal Ormanlar Modeli Karmaşıklık Matrisi",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/rf_bin_conf.png")
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı Rassal Ormanlar Modeli ROC Eğrisi ve AUC Değerleri",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/RandomForestClassifier_binary_roc.png")
```  
### XGBoost {#bin_xgb}

Bu bölümde veri seti üzerinde XGBoost modeli kullanılmış ve çıktıları değerlendirilmiştir.    

#### Hiper Parametre Seçimi  

Daha önce belirlenen parametre uzayını ve Scikit-Learn kütüphanesinde bulunan GridSearchCV algoritması ile en yüksek doğruluk oranı yakalanana kadar çalışması sağlanmıştır.    

```{python echo=FALSE}
#param_grid = {"eta":np.arange(0,.5,0.1),
              #"min_child_weight":np.arange(1,11,1),
              #"max_depth":np.arange(3,11,1),
              #"n_estimators":np.arange(0,500,50)}
#GSC = GridSearchCV(XGBClassifier(eval_metric="auc",use_label_encoder=False,booster="gbtree"),param_grid=param_grid,cv=10,verbose=1,n_jobs=-1,scoring="accuracy").fit(Xbin_train,ybin_train)

#pd.DataFrame(GSC.cv_results_).to_csv("data/XGB_bin_Grid_Res.csv",index=False)

XGB_bin = pd.read_csv("data/XGB_bin_Grid_Res.csv",sep=";")
maxed = XGB_bin.groupby("rank_test_score").max()
maxed = maxed[maxed["mean_test_score"] > 0.75]
plt.figure(figsize=(15,10),dpi=100);
sns.lineplot(x="param_n_estimators",y="mean_test_score",hue="param_eta",data=maxed,err_style=None,palette="husl");
plt.xlabel("Ağaç Sayısı");
plt.ylabel("Eğitim Verisi Doğruluk Skoru (%)");
plt.legend(title="Learning Rate (eta)");
plt.savefig("figure/XGB_bin_Grid_Graph.png");
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı XGBoost Modeli Eğitim Verisi Doğruluk Skorları",out.width="110%",out.height="55%"}
knitr::include_graphics(path="figure/XGB_bin_Grid_Graph.png")
```
```{python echo=FALSE}
#print(f'En İyi Parametreler : {GSC.best_params_}')
```
XGBoost modeli için en yüksek doğruluk oranı aşağıdaki parametreler ile bulunmuştur;  

* 'eta': 0.2  
* 'max_depth': 10  
* 'min_child_weight': 10  
* 'n_estimators': 400  
\newpage  

#### En İyi Parametreli Model  

Bulunan parametrelerle kurulan modelin sınıflandırma metrikleri aşağıdaki gibidir.  

```{python echo=FALSE}
XGB_modelbin = XGBClassifier(eval_metric="auc",
                             use_label_encoder=False,
                             booster="gbtree",
                             eta=0.2,
                             max_depth=10,
                             min_child_weight=10,
                             n_estimators=400).fit(Xbin_train,ybin_train)
ybin_pred = XGB_modelbin.predict(Xbin_test)
print(classification_report(ybin_test,ybin_pred,target_names=["Mild","Mod+Sev"]))
print(f'Balanced Accuracy Score : {balanced_accuracy_score(ybin_test,ybin_pred)}')
```

```{python echo=FALSE,message=FALSE,warning=FALSE}
ConfusionMatrixDisplay(confusion_matrix(ybin_test,ybin_pred),display_labels=["Mild","Mod+Sev"]).plot();
plt.savefig("figure/XGB_bin_conf.png")
plt.close('all')
```
```{python echo=FALSE,message=FALSE,warning=FALSE}
roc_bin(XGB_modelbin)
plt.close('all')
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı XGBoost Modeli Karmaşıklık Matrisi",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/XGB_bin_conf.png")
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı XGBoost Modeli ROC Eğrisi ve AUC Değerleri",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/XGBClassifier_binary_roc.png")
```  


### Neural Network (Yapay Sinir Ağları)  Modeli {#bin_nn}

Bu bölümde veri seti üzerinde yapay sinir ağları modeli kullanılmış ve çıktıları değerlendirilmiştir.  

#### Hiper Parametre Seçimi  

Daha önce belirlenen parametre uzayını ve Scikit-Learn kütüphanesinde bulunan GridSearchCV algoritması ile en yüksek doğruluk oranı yakalanana kadar çalışması sağlanmıştır.  

```{python echo=FALSE}
#params = {"hidden_layer_sizes":np.arange(1,26,1),
          #"learning_rate":["adaptive","constant","invscaling"],
          #"activation":["identity","logistic","tanh","relu"]}
#grid2 = GridSearchCV(MLPClassifier(random_state=13),param_grid=params,cv=10,verbose=1,n_jobs=-1,scoring="accuracy").fit(Xbin_train,ybin_train)
#pd.DataFrame(grid2.cv_results_).to_csv("data/NN_bin_Grid_Res.csv",index=False)
nn_bin = pd.read_csv("data/NN_bin_Grid_Res.csv",sep=";")
plt.figure(figsize=(15,10),dpi=100);
sns.lineplot(x=nn_bin["param_hidden_layer_sizes"],y=nn_bin["mean_test_score"]*100,hue=nn_bin["param_activation"]);
plt.xlabel("Katman Sayısı");
plt.ylabel("Eğitim Verisi Doğruluk Skoru (%)");
plt.legend(title="Aktivasyon Fonksiyonu");
plt.savefig("figure/NN_bin_Grid_Graph.png");
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı Yapay Sinir Ağları Modeli Eğitim Verisi Doğruluk Skorları",out.width="110%",out.height="55%"}
knitr::include_graphics(path="figure/NN_bin_Grid_Graph.png")
```
```{python echo=FALSE}
#print(f'En İyi Parametreler : {grid2.best_params_}')
```  
Yapay sinir ağları modeli için en yüksek doğruluk oranı aşağıdaki parametreler ile bulunmuştur;  

* 'activation': 'relu'  
* 'hidden_layer_sizes': 19  
* 'learning_rate': 'adaptive'  
\newpage  

#### En İyi Parametreli Model  

Bulunan parametrelerle kurulan modelin sınıflandırma metrikleri aşağıdaki gibidir.    

```{python echo=FALSE}
NN_modelbin = MLPClassifier(hidden_layer_sizes=19,
                            learning_rate='adaptive',
                            random_state=13,
                            max_iter=3000).fit(Xbin_train,ybin_train)
ybin_pred = NN_modelbin.predict(Xbin_test)
print(classification_report(ybin_test,ybin_pred,target_names=["Mild","Mod+Sev"]))
print(f'Balanced Accuracy Score : {balanced_accuracy_score(ybin_test,ybin_pred)}')
```

```{python echo=FALSE}
ConfusionMatrixDisplay(confusion_matrix(ybin_test,ybin_pred),display_labels=["Mild","Mod+Sev"]).plot();
plt.savefig("figure/nn_bin_conf.png")
```
```{python echo=FALSE}
roc_bin(NN_modelbin)
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı Yapay Sinir Ağları Modeli Karmaşıklık Matrisi",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/nn_bin_conf.png")
```
```{r echo=FALSE,fig.align="center",fig.cap="İki Sınıflı Yapay Sinir Ağları Modeli ROC Eğrisi ve AUC Değerleri",out.width="105%",out.height="60%"}
knitr::include_graphics(path="figure/MLPClassifier_binary_roc.png")
```
### İki Sınıflı Sınıflama Probleminin Modellerinin Değerlendirdirilmesi
Bölüm \ref{bin_knn}, \ref{bin_rf}, \ref{bin_xgb} ve \ref{bin_nn}'den elde edilen sonuçlar incelenmiş olup, iki sınıflı problem için %82 doğru sınıflama oranları ile XGBoost ve Rassal Ormanlar modelleri en iyi modeller olarak bulunmuştur.  
Bölüm \ref{bin_rf} ve \ref{bin_xgb}'de bulunan performans metrikleri yakından incelendiğinde, XGBoost modeli kesinlik, duyarlılık ve f1-skor metrikleri bakımından Rassal Ormanlar modelinden daha iyi sonuç vermiştir.  
Ciddiyet sınıflandırma probleminin 'Mild' ve 'Moderate + Severe' olacak şekilde 2 sınıfa indirgendiği durumda XGBoost modeli diğer modellerden daha iyi sonuç vermektedir.